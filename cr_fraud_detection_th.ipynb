{"cells":[{"cell_type":"code","execution_count":1,"id":"7957cb85","metadata":{"id":"7957cb85","executionInfo":{"status":"ok","timestamp":1715165475517,"user_tz":-60,"elapsed":5,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# pip install faker"]},{"cell_type":"code","execution_count":2,"id":"6189197c","metadata":{"id":"6189197c","executionInfo":{"status":"ok","timestamp":1715165476880,"user_tz":-60,"elapsed":1367,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import plotly.express as px\n","# from faker import Faker\n","import random"]},{"cell_type":"code","execution_count":3,"id":"580dc333","metadata":{"id":"580dc333","executionInfo":{"status":"ok","timestamp":1715165476880,"user_tz":-60,"elapsed":68,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# # Generate\n","# fake = Faker()\n","# # Set random seed for reproducibility\n","# np.random.seed(42)\n","# # Generate data\n","# num_records = 2000000\n","# dates = [fake.date_between(start_date='-1y', end_date='today') for _ in range(num_records)]\n","# times = [fake.time() for _ in range(num_records)]\n","# customer_ids = [f'C{500000 + i}' for i in range(num_records)]\n","# product_ids = [f'P{random.randint(1, 100)}' for _ in range(num_records)]\n","# amounts = np.random.uniform(150, 500, num_records).round(2)\n","# payment_types = np.random.choice(['Credit Card', 'Debit Card', 'PayPal'], num_records)\n","# countries = np.random.choice(['USA', 'UK', 'Canada', 'Australia', 'France', 'Belgium'], num_records)\n","# merchant_ids = [f'M{random.randint(1, 50)}' for _ in range(num_records)]\n","# statuses = np.random.choice(['Completed', 'Pending', 'Cancelled', 'Refunded', 'Chargeback'], num_records)\n","\n","# # Create DataFrame\n","# df = pd.DataFrame({\n","#     'Transaction_ID': [f'TX{500000 + i}' for i in range(num_records)],\n","#     'Date': dates,\n","#     'Time': times,\n","#     'Customer_ID': customer_ids,\n","#     'Product_ID': product_ids,\n","#     'Amount': amounts,\n","#     'Payment_Type': payment_types,\n","#     'Country': countries,\n","#     'Merchant_ID': merchant_ids,\n","#     'Status': statuses\n","# })\n","\n","# df.to_csv('financial_transactions1.csv', index = False)\n","# print(\"Dataset generated and saved to 'financial_transactions1.csv'\")"]},{"cell_type":"code","execution_count":4,"id":"b82288a2","metadata":{"id":"b82288a2","executionInfo":{"status":"ok","timestamp":1715165476880,"user_tz":-60,"elapsed":67,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# fake = Faker()\n","# # Set random seed for reproducibility\n","# np.random.seed(42)\n","# # Generate data\n","# num_records = 550000\n","# dates = [fake.date_between(start_date='-1y', end_date='today') for _ in range(num_records)]\n","# times = [fake.time() for _ in range(num_records)]\n","# customer_ids = [f'C{1000 + i}' for i in range(num_records)]\n","# product_ids = [f'P{random.randint(1, 100)}' for _ in range(num_records)]\n","# amounts = np.random.uniform(500, 1500, num_records).round(2)\n","# payment_types = np.random.choice(['Credit Card', 'Debit Card', 'PayPal'], num_records)\n","# countries = np.random.choice(['USA', 'UK', 'Canada', 'Australia', 'France', 'Belgium'], num_records)\n","# merchant_ids = [f'M{random.randint(1, 50)}' for _ in range(num_records)]\n","# statuses = np.random.choice(['Completed', 'Pending', 'Cancelled', 'Refunded', 'Chargeback'], num_records)\n","\n","# # Create DataFrame\n","# df = pd.DataFrame({\n","#     'Transaction_ID': [f'TX{50000 + i}' for i in range(num_records)],\n","#     'Date': dates,\n","#     'Time': times,\n","#     'Customer_ID': customer_ids,\n","#     'Product_ID': product_ids,\n","#     'Amount': amounts,\n","#     'Payment_Type': payment_types,\n","#     'Country': countries,\n","#     'Merchant_ID': merchant_ids,\n","#     'Status': statuses\n","# })\n","\n","# df.to_csv('financial_transactions2.csv', index = False)\n","# print(\"Dataset generated and saved to 'financial_transactions2.csv'\")"]},{"cell_type":"code","execution_count":5,"id":"6854193e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"6854193e","executionInfo":{"status":"error","timestamp":1715165476880,"user_tz":-60,"elapsed":66,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}},"outputId":"a387d124-822d-4597-80ab-f97d94c99ec8"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'financial_transactions1.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8feef8268259>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'financial_transactions1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'financial_transactions2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Merge dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfin_tran_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'financial_transactions1.csv'"]}],"source":["df1 = pd.read_csv('financial_transactions1.csv')\n","df2 = pd.read_csv('financial_transactions2.csv')\n","\n","# Merge dataframes\n","fin_tran_df = pd.concat([df1, df2], axis = 0)\n","fin_tran_df.head()"]},{"cell_type":"code","execution_count":null,"id":"e9178ebe","metadata":{"id":"e9178ebe","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["fin_tran_df.info()"]},{"cell_type":"code","execution_count":null,"id":"c928b164","metadata":{"id":"c928b164","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["fin_tran_df_cp = fin_tran_df.copy()\n","fin_tran_df['Date'] = pd.to_datetime(fin_tran_df['Date'], format = '%Y-%m-%d')\n","fin_tran_df['Time'] = pd.to_datetime(fin_tran_df['Time'], format = '%H:%M:%S').dt.time\n","\n","# Extract hour of the day and day of the week\n","fin_tran_df['Hour'] = pd.to_datetime(fin_tran_df['Time'].astype(str), format='%H:%M:%S', errors='coerce').dt.hour\n","fin_tran_df['Day_of_Week'] = fin_tran_df['Date'].dt.dayofweek"]},{"cell_type":"code","execution_count":null,"id":"0085ef26","metadata":{"scrolled":true,"id":"0085ef26","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# Distribution of transactions by hour of the day\n","\n","fin_tran_df1 = fin_tran_df.copy()\n","trans_per_hour = fin_tran_df1['Hour'].value_counts().sort_index()\n","trans_per_hour_per_day = px.line(trans_per_hour, title = 'Distribution of Transactions by Hour',\n","                                      x = trans_per_hour.index, y = trans_per_hour.values)\n","trans_per_hour_per_day.update_layout(xaxis_title = 'Hour of the Day', yaxis_title = 'Number of Transactions')\n","# Show the plots\n","trans_per_hour_per_day.show()"]},{"cell_type":"code","execution_count":null,"id":"ec8caef2","metadata":{"id":"ec8caef2","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# Assuming 'Date' and 'Time' columns are present\n","fin_tran_df2 = fin_tran_df_cp.copy()\n","\n","# Combine Date and Time columns (adjust format string if needed)\n","fin_tran_df2['DateTime'] = pd.to_datetime(fin_tran_df2['Date'] + ' ' + fin_tran_df2['Time'], format='%Y-%m-%d %H:%M:%S')  # Adjust format if necessary\n","\n","# Set the datetime column as the index\n","fin_tran_df2.set_index('DateTime', inplace=True)\n","\n","# Resample by day and count the number of transactions\n","time_series_day = px.line(fin_tran_df2.resample('D').size(), title='Time Series of Transactions by Day')\n","time_series_day.update_layout(xaxis_title='Date', yaxis_title='Number of Transactions')\n"]},{"cell_type":"code","execution_count":null,"id":"8f6048e3","metadata":{"id":"8f6048e3","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["fin_tran_pivot = fin_tran_df1.pivot_table(index = 'Hour', columns = 'Day_of_Week', aggfunc = 'size')\n","fin_tran_pivot.head()"]},{"cell_type":"code","execution_count":null,"id":"8b007593","metadata":{"id":"8b007593","executionInfo":{"status":"aborted","timestamp":1715165476881,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# Heatmap of transactions by hour of the day and day of the week\n","fin_tran_pivot = fin_tran_df1.pivot_table(index = 'Hour', columns = 'Day_of_Week', aggfunc = 'size')\n","fig = px.imshow(fin_tran_pivot,\n","                labels = dict(x = \"Day of Week\", y = \"Time of Day\", color_continuous_scale = 'Blues'),\n","                x = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n","                y = [0, 1, 2, 3, 4, 5, 6, 7,\n","                     8, 9, 10, 11, 12, 13, 14, 15, 16,\n","                     17, 18, 19, 20, 21, 22, 23]\n","               )\n","fig.update_xaxes(side = \"top\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"c5ab6cc4","metadata":{"id":"c5ab6cc4","executionInfo":{"status":"aborted","timestamp":1715165476882,"user_tz":-60,"elapsed":19,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["# Assuming 'Amount' and 'Payment_Type' columns exist\n","fin_tran_df2 = fin_tran_df.copy()\n","\n","# Box plot with Plotly Express\n","box_pmt_amt = px.box(fin_tran_df2, x = 'Payment_Type', y = 'Amount', title = 'Transaction Amount Distribution by Payment Type')\n","\n","box_pmt_amt.update_layout(xaxis_title = 'Payment Type', yaxis_title = 'Transaction Amount')\n","box_pmt_amt.show()"]},{"cell_type":"code","execution_count":null,"id":"b0318775","metadata":{"id":"b0318775","executionInfo":{"status":"aborted","timestamp":1715165476882,"user_tz":-60,"elapsed":18,"user":{"displayName":"Seghe Momodu","userId":"16427622317557087578"}}},"outputs":[],"source":["fin_tran_df2.columns"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}